import os
import pickle
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# --- Configuration ---
BASE_DIR = os.path.dirname(__file__)
INDEX_PATH = os.path.join(BASE_DIR, "..", "index", "index.faiss")
METADATA_PATH = os.path.join(BASE_DIR, "..", "index", "metadata.pkl")

print("ğŸ” Loading FAISS index and metadata...")
index = faiss.read_index(INDEX_PATH)
with open(METADATA_PATH, "rb") as f:
    metadata = pickle.load(f)

chunks = metadata["chunks"]
model = SentenceTransformer("all-MiniLM-L6-v2")

# --- Query ---
query = input("\nğŸ” Enter your query: ").strip()
if not query:
    print("âš ï¸ Empty query. Exiting.")
    exit()

print("ğŸ“¡ Embedding query...")
query_embedding = model.encode(query).astype("float32")

# --- Search ---
k = 3  # number of results
print(f"ğŸ” Searching top {k} matches...")
distances, indices = index.search(np.array([query_embedding]), k)

# --- Show Results ---
print("\nğŸ“Œ Top Results:")
for rank, (idx, dist) in enumerate(zip(indices[0], distances[0]), 1):
    print(f"\n[Match #{rank}] (Distance: {dist:.4f})")
    print(chunks[idx])
